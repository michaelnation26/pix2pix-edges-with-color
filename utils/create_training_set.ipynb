{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pyimagesearch.com/2019/03/04/holistically-nested-edge-detection-with-opencv-and-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from keras.preprocessing.image import load_img, save_img\n",
    "from keras.utils import get_file\n",
    "import numpy as np\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change current directory to project root\n",
    "current_dir = os.getcwd().split('/')[-1]\n",
    "if current_dir != 'pix2pix-edges-with-color': \n",
    "    %cd '..'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Zappos50K dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_file(f'{config.ZAPPOS_DATASET_NAME}.zip', config.ZAPPOS_DATASET_URL, extract=True, \n",
    "         cache_dir='.', cache_subdir='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download HED pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_file(config.HED_MODEL_FILENAME, config.HED_MODEL_URL, cache_dir=config.HED_MODEL_DIR, cache_subdir='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HED model custom crop layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropLayer(object):\n",
    "    def __init__(self, params, blobs):\n",
    "        # initialize our starting and ending (x, y) coordinates of the crop\n",
    "        self.startX = 0\n",
    "        self.startY = 0\n",
    "        self.endX = 0\n",
    "        self.endY = 0\n",
    "        \n",
    "    def getMemoryShapes(self, inputs):\n",
    "        # the crop layer will receive two inputs -- we need to crop\n",
    "        # the first input blob to match the shape of the second one,\n",
    "        # keeping the batch size and number of channels\n",
    "        (inputShape, targetShape) = (inputs[0], inputs[1])\n",
    "        (batchSize, numChannels) = (inputShape[0], inputShape[1])\n",
    "        (H, W) = (targetShape[2], targetShape[3])\n",
    "\n",
    "        # compute the starting and ending crop coordinates\n",
    "        self.startX = int((inputShape[3] - targetShape[3]) / 2)\n",
    "        self.startY = int((inputShape[2] - targetShape[2]) / 2)\n",
    "        self.endX = self.startX + W\n",
    "        self.endY = self.startY + H\n",
    "\n",
    "        # return the shape of the volume (we'll perform the actual\n",
    "        # crop during the forward pass\n",
    "        return [[batchSize, numChannels, H, W]]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # use the derived (x, y)-coordinates to perform the crop\n",
    "        return [inputs[0][:, :, self.startY:self.endY,\n",
    "                self.startX:self.endX]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges(img, hed_model):\n",
    "    \"\"\"Edges in image are detected using HED model. \n",
    "    \n",
    "    Returns:\n",
    "        3-dimensional grayscale image of detected edges (white background, black foreground).\n",
    "    \"\"\"\n",
    "    blob = cv2.dnn.blobFromImage(img, mean=(104.00698793, 116.66876762, 122.67891434))\n",
    "    hed_model.setInput(blob)\n",
    "    img_edges = hed_model.forward()\n",
    "    img_edges = img_edges[0, 0]\n",
    "    img_edges = (255 * img_edges).astype(\"uint8\")\n",
    "    img_edges = cv2.bitwise_not(img_edges) # invert black/white\n",
    "    \n",
    "    # 2D grayscale -> 3D\n",
    "    img_edges = np.expand_dims(img_edges, axis=-1)\n",
    "    img_edges = np.repeat(img_edges, config.IMG_N_CHANNELS, axis=-1)\n",
    "    \n",
    "    return img_edges\n",
    "\n",
    "def get_shoe_model_id_to_filepaths_dict(data_dir):\n",
    "    \"\"\"The naming convention for each image in the Zappos dataset is SHOE_MODEL_ID.SHOE_COLOR_PATTERN_ID.jpg.\n",
    "    Only images with a minimum frequency of two shoe model ids  are kept. \n",
    "\n",
    "    e.g. For the list of image names below, image 2.1.jpg will not be kept since the shoe model id only occurs once.\n",
    "    1.1.jpg\n",
    "    1.2.jpg\n",
    "    2.1.jpg\n",
    "    \"\"\"\n",
    "    model_id_to_filepaths = {}\n",
    "    for filepath in glob.glob(f'{data_dir}/*.jpg'):\n",
    "        filename = os.path.basename(filepath)\n",
    "        model_id, pattern_id = filename.split('.')[:2]\n",
    "        filepaths = model_id_to_filepaths.get(model_id, [])\n",
    "        filepaths.append(filepath)\n",
    "        model_id_to_filepaths[model_id] = filepaths\n",
    "    \n",
    "    model_id_to_filepaths = {model_id: filepaths \n",
    "                             for model_id, filepaths in model_id_to_filepaths.items()\n",
    "                             if len(filepaths) >= config.ZAPPOS_DATASET_MIN_SHOE_MODEL_ID_COUNT}\n",
    "    \n",
    "    return model_id_to_filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HED model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.dnn_registerLayer(\"Crop\", CropLayer)\n",
    "hed_model = cv2.dnn.readNetFromCaffe(config.HED_MODEL_PROTOTXT_FILEPATH, config.HED_MODEL_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create source (edge) images and copy target images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f'{config.ZAPPOS_DATASET_SNEAKERS_DIR}/Nike'\n",
    "model_id_to_filepaths = get_shoe_model_id_to_filepaths_dict(data_dir)\n",
    "\n",
    "for filepaths in model_id_to_filepaths.values():\n",
    "    img_first = load_img(filepaths[0], target_size=(config.IMG_HEIGHT, config.IMG_WIDTH))\n",
    "    img_first = np.array(img_first)\n",
    "    img_edges = detect_edges(img_first, hed_model)\n",
    "    \n",
    "    for filepath in filepaths:\n",
    "        filename = os.path.basename(filepath)\n",
    "        \n",
    "        img_source_filepath = os.path.join(config.TRAINING_SOURCE_DIR, filename)\n",
    "        save_img(img_source_filepath, img_edges)\n",
    "        \n",
    "        img_target = load_img(filepath, target_size=(config.IMG_HEIGHT, config.IMG_WIDTH))\n",
    "        img_target = np.array(img_target)\n",
    "        img_target_filepath = os.path.join(config.TRAINING_TARGET_DIR, filename)\n",
    "        save_img(img_target_filepath, img_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
