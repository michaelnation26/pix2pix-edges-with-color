{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pyimagesearch.com/2019/03/04/holistically-nested-edge-detection-with-opencv-and-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download HED pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from urllib.request import urlretrieve\n",
    "\n",
    "# urlretrieve(HED_MODEL_URL, HED_MODEL_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from keras.preprocessing.image import load_img\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HED_MODEL_URL = 'http://vcl.ucsd.edu/hed/hed_pretrained_bsds.caffemodel'\n",
    "HED_MODEL_FILEPATH = 'hed_model/hed_pretrained_bsds.caffemodel'\n",
    "HED_MODEL_PROTOTXT_FILEPATH = 'hed_model/deploy.prototxt'\n",
    "\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "IMG_N_CHANNELS = 3\n",
    "\n",
    "USER_COLOR_POINTS_PER_IMG = 50\n",
    "USER_COLOR_POINTS_CIRCLE_RADIUS = 3\n",
    "\n",
    "TRAINING_DIR = '../data/training'\n",
    "TRAINING_TARGET_DIR = f'{TRAINING_DIR}/target'\n",
    "TRAINING_SOURCE_EDGES_DIR = f'{TRAINING_DIR}/source_edges'\n",
    "TRAINING_SOURCE_EDGES_COLOR_DIR = f'{TRAINING_DIR}/source_edges+color'\n",
    "TRAINING_COMPRESSED_DATASET_FILEPATH = f'{TRAINING_DIR}/training_set.npz'\n",
    "\n",
    "VALIDATION_DIR = '../data/validation'\n",
    "VALIDATION_TARGET_DIR = f'{VALIDATION_DIR}/target'\n",
    "VALIDATION_SOURCE_EDGES_DIR = f'{VALIDATION_DIR}/source_edges'\n",
    "VALIDATION_SOURCE_EDGES_COLOR_DIR = f'{VALIDATION_DIR}/source_edges+color'\n",
    "VALIDATION_COMPRESSED_DATASET_FILEPATH = f'{VALIDATION_DIR}/validation_set.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropLayer(object):\n",
    "    def __init__(self, params, blobs):\n",
    "        # initialize our starting and ending (x, y) coordinates of the crop\n",
    "        self.startX = 0\n",
    "        self.startY = 0\n",
    "        self.endX = 0\n",
    "        self.endY = 0\n",
    "        \n",
    "    def getMemoryShapes(self, inputs):\n",
    "        # the crop layer will receive two inputs -- we need to crop\n",
    "        # the first input blob to match the shape of the second one,\n",
    "        # keeping the batch size and number of channels\n",
    "        (inputShape, targetShape) = (inputs[0], inputs[1])\n",
    "        (batchSize, numChannels) = (inputShape[0], inputShape[1])\n",
    "        (H, W) = (targetShape[2], targetShape[3])\n",
    "\n",
    "        # compute the starting and ending crop coordinates\n",
    "        self.startX = int((inputShape[3] - targetShape[3]) / 2)\n",
    "        self.startY = int((inputShape[2] - targetShape[2]) / 2)\n",
    "        self.endX = self.startX + W\n",
    "        self.endY = self.startY + H\n",
    "\n",
    "        # return the shape of the volume (we'll perform the actual\n",
    "        # crop during the forward pass\n",
    "        return [[batchSize, numChannels, H, W]]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # use the derived (x, y)-coordinates to perform the crop\n",
    "        return [inputs[0][:, :, self.startY:self.endY,\n",
    "                self.startX:self.endX]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges(img, hed_model):\n",
    "    \"\"\"Edges in image are detected using HED model. \n",
    "    \n",
    "    Returns:\n",
    "        Grayscale image of detected edges (white background, black foreground).\n",
    "    \"\"\"\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        img, size=(IMG_HEIGHT, IMG_WIDTH), mean=(104.00698793, 116.66876762, 122.67891434))\n",
    "    hed_model.setInput(blob)\n",
    "    img_edges = hed_model.forward()\n",
    "    img_edges = img_edges[0, 0]\n",
    "    img_edges = (255 * img_edges).astype(\"uint8\")\n",
    "    img_edges = cv2.bitwise_not(img_edges) # invert black/white\n",
    "    \n",
    "    return img_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained HED model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.dnn_registerLayer(\"Crop\", CropLayer)\n",
    "hed_model = cv2.dnn.readNetFromCaffe(HED_MODEL_PROTOTXT_FILEPATH, HED_MODEL_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate edge images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edge_images(target_dir, source_edges_dir):\n",
    "    filenames = [os.path.basename(fp) for fp in glob.glob(f'{target_dir}/*.jpg')]\n",
    "    for idx, filename in enumerate(filenames):\n",
    "        filepath_target = os.path.join(target_dir, filename)\n",
    "        img_target = load_img(filepath_target)\n",
    "        img_target = np.array(img_target)\n",
    "\n",
    "        img_source_edges = detect_edges(img_target, hed_model)\n",
    "        img_source_edges_filepath = os.path.join(source_edges_dir, filename)\n",
    "        cv2.imwrite(img_source_edges_filepath, img_source_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_edge_images(TRAINING_TARGET_DIR, TRAINING_SOURCE_EDGES_DIR)\n",
    "generate_edge_images(VALIDATION_TARGET_DIR, VALIDATION_SOURCE_EDGES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress target and source images into single numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_dataset(target_dir, source_edges_dir, compressed_dataset_filepath):\n",
    "    filenames = [os.path.basename(fp) for fp in glob.glob(f'{source_edges_dir}/*.jpg')]\n",
    "    n_images = len(filenames)\n",
    "    src_imgs = np.empty((n_images, IMG_HEIGHT, IMG_WIDTH, IMG_N_CHANNELS), dtype=np.uint8)\n",
    "    target_imgs = np.empty((n_images, IMG_HEIGHT, IMG_WIDTH, IMG_N_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "    for idx, filename in enumerate(filenames):\n",
    "        filepath_source_edges = os.path.join(source_edges_dir, filename)\n",
    "        img_source_edges = load_img(filepath_source_edges)\n",
    "        src_imgs[idx] = np.array(img_source_edges)\n",
    "\n",
    "        filepath_target = os.path.join(target_dir, filename)\n",
    "        img_target = load_img(filepath_target)\n",
    "        img_target = np.array(img_target)\n",
    "        target_imgs[idx] = cv2.resize(img_target, (IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "    print(f'source images: {src_imgs.shape}, target images: {target_imgs.shape}')\n",
    "    np.savez_compressed(compressed_dataset_filepath, source=src_imgs, target=target_imgs)\n",
    "    print('save complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_dataset(TRAINING_TARGET_DIR, TRAINING_SOURCE_EDGES_DIR, TRAINING_COMPRESSED_DATASET_FILEPATH)\n",
    "compress_dataset(VALIDATION_TARGET_DIR, VALIDATION_SOURCE_EDGES_DIR, VALIDATION_COMPRESSED_DATASET_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _draw_color_circle_on_src_img(img_src, img_target, center_y, center_x):\n",
    "    assert(img_src.shape == img_target, \"Image source and target must have same shape.\")\n",
    "    \n",
    "    color = _get_mean_color(img_target, center_y, center_x)\n",
    "    cv2.circle(img_src, (center_x, center_y), USER_COLOR_POINTS_CIRCLE_RADIUS, color, cv2.FILLED)\n",
    "\n",
    "def _get_mean_color(img, center_y, center_x):\n",
    "    radius = USER_COLOR_POINTS_CIRCLE_RADIUS\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    y0 = max(0, center_y-radius)\n",
    "    y1 = min(h, center_y+radius)\n",
    "    x0 = max(0, center_x-radius)\n",
    "    x1 = min(w, center_x+radius)\n",
    "    mean_color = np.mean(img[y0:y1, x0:x1], axis=(0, 1)).astype(np.uint8)\n",
    "    \n",
    "    return mean_color.tolist()\n",
    "    \n",
    "def draw_color_circles_on_src_img(img_src, img_target):\n",
    "    non_white_coords = np.where(~np.all(img_target == 255, axis=2))\n",
    "    idxs = np.random.choice(len(non_white_coords[0]), USER_COLOR_POINTS_PER_IMG, replace=False)\n",
    "    for idx in idxs:\n",
    "        _draw_color_circle_on_src_img(\n",
    "            img_src, img_target, center_y=non_white_coords[0][idx], center_x=non_white_coords[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [os.path.basename(fp) for fp in glob.glob(f'{TRAINING_SOURCE_EDGES_DIR}/*.jpg')]\n",
    "idx = 27\n",
    "target_fp = os.path.join(TRAINING_TARGET_DIR, filenames[idx])\n",
    "src_fp = os.path.join(TRAINING_SOURCE_EDGES_DIR, filenames[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_target = cv2.imread(target_fp)\n",
    "img_target = cv2.resize(img_target, (IMG_WIDTH, IMG_HEIGHT))\n",
    "img_src = cv2.imread(src_fp)\n",
    "img_src = cv2.resize(img_src, (IMG_WIDTH, IMG_HEIGHT))\n",
    "draw_color_circles_on_src_img(img_src, img_target)\n",
    "\n",
    "\n",
    "cv2.imwrite('a.jpg', img_src)\n",
    "cv2.imwrite('b.jpg', img_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
